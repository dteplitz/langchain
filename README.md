# LangChain Chat System - Stage 1

A LangChain-based chat system with intelligent agents, built with FastAPI and modern Python practices.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI App   â”‚â”€â”€â”€â–¶â”‚  Simple Chain   â”‚â”€â”€â”€â–¶â”‚ Curator Agent   â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ /chat         â”‚    â”‚ â€¢ Memory Mgmt   â”‚    â”‚ â€¢ Input Clean   â”‚
â”‚ â€¢ /health       â”‚    â”‚ â€¢ Error Handlingâ”‚    â”‚ â€¢ Validation    â”‚
â”‚ â€¢ CORS          â”‚    â”‚ â€¢ Logging       â”‚    â”‚ â€¢ JSON Output   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SQLite DB     â”‚    â”‚   Groq LLM      â”‚    â”‚   Logging       â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Chat History  â”‚    â”‚ â€¢ llama3-8b     â”‚    â”‚ â€¢ Structured    â”‚
â”‚ â€¢ Session Mgmt  â”‚    â”‚ â€¢ Fast Response â”‚    â”‚ â€¢ Request IDs   â”‚
â”‚ â€¢ Persistence   â”‚    â”‚ â€¢ Configurable  â”‚    â”‚ â€¢ Performance   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Features (Stage 1)

- **Curator Agent**: Cleans and validates user input
- **FastAPI Integration**: RESTful API with OpenAPI documentation
- **SQLite Memory**: Persistent conversation history
- **Structured Logging**: Request tracking and performance metrics
- **Error Handling**: Comprehensive error management
- **CORS Support**: Cross-origin resource sharing
- **Type Safety**: Full type hints and Pydantic validation

## ğŸ“‹ Prerequisites

- Python 3.8+
- Groq API key (get one at [groq.com](https://groq.com))

## ğŸ› ï¸ Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd langchain
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure environment**
   ```bash
   cp env.example .env
   # Edit .env with your Groq API key
   ```

4. **Set your Groq API key**
   ```bash
   # Edit .env file
   GROQ_API_KEY=your_actual_groq_api_key_here
   ```

## ğŸƒâ€â™‚ï¸ Running the Application

### Development Mode
```bash
python -m src.main
```

### Production Mode
```bash
uvicorn src.main:app --host 0.0.0.0 --port 8000
```

### With Debug Logging
```bash
DEBUG=true python -m src.main
```

## ğŸ“š API Documentation

Once running, visit:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **Health Check**: http://localhost:8000/health

## ğŸ”§ API Usage

### Chat Endpoint

**POST** `/chat`

```json
{
  "message": "What is the capital of France?",
  "session_id": "user_123",
  "debug": false
}
```

**Response:**
```json
{
  "response": "I understand your question: What is the capital of France?. This would be processed by the full chain in later stages.",
  "session_id": "user_123",
  "request_id": "req_456",
  "processing_time": 1.23,
  "metadata": {
    "agent_used": "curator",
    "is_valid": true,
    "confidence": 0.95,
    "content_type": "question",
    "validation_errors": [],
    "stage": "stage_1"
  }
}
```

## ğŸ—ï¸ Project Structure

```
langchain/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ config.py              # Configuration management
â”‚   â”œâ”€â”€ models.py              # Pydantic models
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ curator_agent.py   # Curator agent implementation
â”‚   â”œâ”€â”€ chains/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ simple_chain.py    # Simple chain for Stage 1
â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ conversation_memory.py  # SQLite memory management
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ curator_prompts.py # Curator agent prompts
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ llm_client.py      # Groq LLM client
â”‚       â””â”€â”€ logger.py          # Structured logging
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ env.example               # Environment variables template
â”œâ”€â”€ chat_memory.db            # SQLite database (created automatically)
â””â”€â”€ README.md                 # This file
```

## ğŸ” Testing the System

### 1. Health Check
```bash
curl http://localhost:8000/health
```

### 2. Simple Chat
```bash
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Hello, how are you?",
    "session_id": "test_user"
  }'
```

### 3. Debug Mode
```bash
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "What is Python?",
    "session_id": "debug_user",
    "debug": true
  }'
```

## ğŸ§ª Validation Examples

The Curator Agent will validate different types of input:

- **Valid Questions**: "What is the capital of France?"
- **Valid Statements**: "I like programming"
- **Invalid Content**: Messages with inappropriate content
- **Empty Messages**: Will be flagged as invalid

## ğŸ“Š Monitoring

The system provides comprehensive logging:

- **Request Tracking**: Each request gets a unique ID
- **Performance Metrics**: Processing time for each agent
- **Error Logging**: Detailed error information with context
- **Agent Responses**: Logged with metadata and confidence scores

## ğŸ”§ Configuration

Key configuration options in `.env`:

```bash
# LLM Settings
MODEL_NAME=llama3-8b-8192    # Groq model to use
TEMPERATURE=0.7              # Response creativity (0.0-2.0)
MAX_TOKENS=1000              # Maximum response length

# Logging
LOG_LEVEL=INFO               # Logging level
DEBUG=false                  # Debug mode

# Database
DATABASE_URL=sqlite:///./chat_memory.db
```

## ğŸš§ Stage 1 Limitations

This is the first stage of development. Current limitations:

- Only the Curator Agent is implemented
- No actual response generation (placeholder responses)
- Basic chain orchestration
- No tools or external APIs

## ğŸ”® Next Stages

**Stage 2**: Add Processor and Response agents with tools
**Stage 3**: Complete RunnableSequence with fallbacks and callbacks

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ†˜ Support

For issues and questions:
1. Check the API documentation at `/docs`
2. Review the logs for error details
3. Ensure your Groq API key is valid
4. Verify all dependencies are installed 